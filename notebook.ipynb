{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using transfer learning with keras, to find out if a certain image depicts a happy person or not. There might be better or more efficient approaches to doing this, and maybe this turns out to be overkill. However, I wish to know if this would work well. \n",
    "I'll be using pre-trained inception model v3 and add a couple of FC layers at the end to check how well it does. \n",
    "For this I have a dataset of about 250 images scrapped off the internet. I would suggest you to not use google since it is biased in the sense you would not get asians or indians pictures in the pool. Bing is better. Best would be instagram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import os, cv2, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/paperspace/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# First attempt will be with the inception v3 model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './dataset/'\n",
    "CLASSES = ['happy', 'nothappy']\n",
    "\n",
    "# Image dimentions for resizing:\n",
    "ROWS = 299  # Default input of inception v3 \n",
    "COLS = 299 # Default input of inception v3 \n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 photos of happy\n",
      "190 photos of nothappy\n"
     ]
    }
   ],
   "source": [
    "def get_images(emotion):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    emotion_dir = TRAIN_DIR+'{}'.format(emotion)\n",
    "    images = [emotion+'/'+im for im in os.listdir(emotion_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "\n",
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for emotion in CLASSES:\n",
    "    emotion_files = get_images(emotion)\n",
    "    files.extend(emotion_files)\n",
    "    \n",
    "    y_emotion = np.tile(emotion, len(emotion_files))\n",
    "    y_all.extend(y_emotion)\n",
    "    print(\"{0} photos of {1}\".format(len(emotion_files), emotion))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 446\n",
      "(446, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "       'happy', 'happy', 'happy', 'happy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy', 'nothappy', 'nothappy',\n",
       "       'nothappy', 'nothappy', 'nothappy'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = LabelEncoder().fit_transform(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = np_utils.to_categorical(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.15, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 299, 299, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 299, 299, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that as a part of the preprocessing we have already scaled down the images to fit\n",
    "# the inception model input requirements.\n",
    "\n",
    "# create the base pre-trained model from Keras library\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False) #change weights to 'imagenet' on your local build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer for the FISH_CLASSES = 8 we are trying to predict\n",
    "predictions = Dense(len(CLASSES), activation='softmax', name='prediction_layer')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first N layers and unfreeze the rest:\n",
    "\n",
    "N=172\n",
    "\n",
    "for layer in model.layers[:N]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[N:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 76 samples\n",
      "Epoch 1/20\n",
      "303/303 [==============================] - 17s - loss: 0.6932 - acc: 0.5743 - val_loss: 0.7447 - val_acc: 0.4342\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 8s - loss: 0.6547 - acc: 0.6073 - val_loss: 0.7352 - val_acc: 0.5395\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 8s - loss: 0.6215 - acc: 0.6634 - val_loss: 0.7282 - val_acc: 0.5395\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 8s - loss: 0.5909 - acc: 0.6964 - val_loss: 0.7125 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 7s - loss: 0.5680 - acc: 0.7096 - val_loss: 0.6597 - val_acc: 0.6184\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 7s - loss: 0.5294 - acc: 0.8086 - val_loss: 0.6475 - val_acc: 0.6579\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 8s - loss: 0.5160 - acc: 0.7921 - val_loss: 0.6405 - val_acc: 0.6447\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 8s - loss: 0.4992 - acc: 0.8218 - val_loss: 0.5924 - val_acc: 0.7237\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 7s - loss: 0.4827 - acc: 0.8350 - val_loss: 0.5844 - val_acc: 0.7105\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 7s - loss: 0.4522 - acc: 0.8845 - val_loss: 0.5728 - val_acc: 0.7237\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 8s - loss: 0.4280 - acc: 0.8878 - val_loss: 0.5638 - val_acc: 0.7237\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 7s - loss: 0.4048 - acc: 0.9010 - val_loss: 0.5664 - val_acc: 0.7500\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 8s - loss: 0.4028 - acc: 0.8779 - val_loss: 0.5510 - val_acc: 0.7368\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 8s - loss: 0.3907 - acc: 0.8944 - val_loss: 0.5562 - val_acc: 0.7105\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 8s - loss: 0.3746 - acc: 0.9142 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 8s - loss: 0.3413 - acc: 0.9274 - val_loss: 0.5409 - val_acc: 0.7237\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 8s - loss: 0.3322 - acc: 0.9208 - val_loss: 0.5295 - val_acc: 0.7500\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 8s - loss: 0.3174 - acc: 0.9439 - val_loss: 0.5345 - val_acc: 0.7368\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 8s - loss: 0.3068 - acc: 0.9307 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 8s - loss: 0.3050 - acc: 0.9307 - val_loss: 0.5195 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4cffb329e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, epochs=20,\n",
    "              validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s     \n",
      "Validation Logloss:  [0.50178037917436058, 0.74626866427820115]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_valid, y_valid, batch_size=20)\n",
    "print (\"Validation Logloss: \", loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', '00000PORTRAIT_00000_BURST20180218233533250.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DIR = './test/'\n",
    "os.listdir(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 299, 299, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_files = [im for im in os.listdir(TEST_DIR) if im.endswith('jpg')]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(TEST_DIR+im)\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89147002,  0.10852993],\n",
       "       [ 0.49945959,  0.50054044],\n",
       "       [ 0.19927965,  0.80072033],\n",
       "       [ 0.6402328 ,  0.35976717],\n",
       "       [ 0.44079015,  0.55920982],\n",
       "       [ 0.63479054,  0.36520946],\n",
       "       [ 0.59471244,  0.40528759]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>happy</th>\n",
       "      <th>nothappy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy-group.jpg</td>\n",
       "      <td>0.891470</td>\n",
       "      <td>0.108530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad-baby-crying.jpg</td>\n",
       "      <td>0.499460</td>\n",
       "      <td>0.500540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad-bearded-man.jpg</td>\n",
       "      <td>0.199280</td>\n",
       "      <td>0.800720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy-lady.jpg</td>\n",
       "      <td>0.640233</td>\n",
       "      <td>0.359767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad-kid-crying.jpg</td>\n",
       "      <td>0.440790</td>\n",
       "      <td>0.559210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image     happy  nothappy\n",
       "0      happy-group.jpg  0.891470  0.108530\n",
       "1  sad-baby-crying.jpg  0.499460  0.500540\n",
       "2  sad-bearded-man.jpg  0.199280  0.800720\n",
       "3       happy-lady.jpg  0.640233  0.359767\n",
       "4   sad-kid-crying.jpg  0.440790  0.559210"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds, columns=CLASSES)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we see, the results are good. They would be even better if we train for more epochs. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
